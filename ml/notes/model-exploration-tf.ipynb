{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Explore models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwvycpgPS9gsvERshUaxmi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frnkly/jayne-eats/blob/main/ml/notes/model-exploration-tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3roT45bqR-vs"
      },
      "source": [
        "# Model Exploration\n",
        "\n",
        "- [Choosing the right estimator](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
        "- [Tuning the hyper-parameters of an estimator using grid search](https://scikit-learn.org/stable/modules/grid_search.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvG0bIB_UzD7"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0Uv0gItdoSG",
        "outputId": "5e65b416-0847-4ccf-915f-85d2c0028dae"
      },
      "source": [
        "# Data samples, organized as: [classification, consistency, temperature, [ingredients]].\n",
        "foods = [\n",
        "  # Pizzas\n",
        "  [0, 'solid', 'warm', ['bell pepper', 'cheese', 'flour', 'garlic', 'oil', 'olive', 'onion', 'salt', 'sugar', 'tomato']], # Olives\n",
        "  [0, 'solid', 'warm', ['anchovy', 'bell pepper', 'cheese', 'flour', 'garlic', 'mayonnaise', 'oil', 'olive', 'onion', 'salt', 'spinach', 'sugar']], # Anchovies\n",
        "  [0, 'solid', 'warm', ['apple', 'coriander', 'cheese', 'flour', 'garlic', 'oil', 'onion', 'salt', 'sugar']], # Apple & goat cheese\n",
        "  [1, 'solid', 'warm', ['arugula', 'bell pepper', 'cheese', 'coriander', 'flour', 'garlic', 'oil', 'onion', 'salt', 'spinach', 'sugar', 'tomato']], # Arugula\n",
        "  [1, 'solid', 'warm', ['bell pepper', 'cheese', 'flour', 'garlic', 'mushroom', 'oil', 'onion', 'salt', 'sugar']], # Mushroom\n",
        "  [1, 'solid', 'warm', ['cheese', 'flour', 'garlic', 'oil', 'onion', 'salt', 'sugar', 'tomato']], # Cheese\n",
        "\n",
        "  # Products\n",
        "  # [1, 'crunchy', 'normal', ['anise', 'baking powder', 'egg', 'flour', 'oil', 'sugar']], # Biscotti\n",
        "  # [1, 'crunchy', 'cool', ['almond', 'barley malt', 'milk', 'rice', 'salt', 'sugar', 'wheat bran', 'whole grain wheat']], # Vanilla almond Special K\n",
        "\n",
        "  # Smoothies & milkshakes\n",
        "  [1, 'chewy', 'cool', ['cookies', 'milk', 'skim milk', 'sugar', 'vanilla']], # Oreo ice cream\n",
        "  [0, 'thick', 'cool', ['blueberry', 'pineapple', 'strawberry']],\n",
        "  [0, 'thick', 'cool', ['blueberry', 'kiwi', 'strawberry']],\n",
        "  [0, 'thick', 'cool', ['chocolate', 'milk', 'vanilla']],\n",
        "  [0, 'thick', 'cool', ['banana', 'chocolate', 'milk', 'vanilla']],\n",
        "  [0, 'thick', 'cool', ['milk', 'strawberry', 'vanilla']],\n",
        "  [1, 'thick', 'cool', ['banana', 'mango', 'pineapple']],\n",
        "  [1, 'thick', 'cool', ['blueberry', 'kiwi', 'mango', 'pineapple']],\n",
        "  [1, 'thick', 'cool', ['banana', 'milk', 'strawberry', 'vanilla']],\n",
        "  [1, 'thick', 'cool', ['banana', 'milk', 'kiwi', 'vanilla']],\n",
        "\n",
        "  # Soups & chilis\n",
        "  [0, 'mashed', 'warm', ['bay leaf', 'chickpea', 'chili', 'coriander', 'cumin', 'garlic', 'ginger', 'oil', 'onion', 'salt', 'tomato', 'tumeric']], # Chole chickpea curry\n",
        "  [0, 'mashed', 'warm', ['black pepper', 'chickpea', 'chili', 'coriander', 'cumin', 'garlic', 'ginger', 'oil', 'onion', 'potato', 'salt', 'spinach', 'tomato', 'tumeric']], # Sweet potato curry\n",
        "  [1, 'mashed', 'warm', ['black pepper', 'butter', 'cheese', 'coriander', 'garlic', 'potato', 'salt']], # Mash potatoes\n",
        "  [1, 'mashed', 'warm', ['bean', 'black pepper', 'carrot', 'chili', 'garlic', 'onion', 'potato', 'salt', 'tomato', 'tumeric']], # Chili\n",
        "  [0, 'liquid', 'warm', ['black pepper', 'butter', 'flour', 'garlic', 'onion', 'peanut', 'salt']], # Peanut soup\n",
        "  [1, 'thick', 'warm', ['black pepper', 'carrot', 'chili', 'garlic', 'onion', 'potato', 'salt', 'squash']], # Butternut squash soup\n",
        "\n",
        "  # Miscellaneous (stuff made out of ingredients from above)\n",
        "  [1, 'crunchy', 'normal', ['almond', 'apple', 'arugula', 'cranberry', 'oil', 'salt']], # Arugula salad\n",
        "  [1, 'solid', 'warm', ['black pepper', 'cheese', 'egg', 'garlic', 'mushroom', 'oil', 'onion', 'red pepper', 'salt', 'spinach']], # Mushroom spinach omelet\n",
        "  [1, 'solid', 'warm', ['bean', 'black pepper', 'oil', 'onion', 'rice', 'salt', 'tumeric']], # Rice and beans\n",
        "  [1, 'solid', 'warm', ['black pepper', 'mushroom', 'oil', 'onion', 'pea', 'rice', 'salt']], # Riz djondjon\n",
        "  [1, 'solid', 'cool', ['banana', 'butter', 'egg', 'flour', 'milk', 'salt', 'strawberry']], # Crepes\n",
        "  [0, 'solid', 'warm', ['black pepper', 'oil', 'okra', 'onion', 'rice', 'salt', 'spinach']], # Kalalou\n",
        "]\n",
        "\n",
        "print('Size of data set:', len(foods))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of data set: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlOjXQLAKc1k"
      },
      "source": [
        "# General utility functions.\n",
        "import numpy as np\n",
        "\n",
        "def get_descriptions(samples):\n",
        "  \"\"\"Retrieves food descriptions from a data set.\"\"\"\n",
        "\n",
        "  return list(map(lambda sample: sample[1:3], foods))\n",
        "\n",
        "def get_ingredients(samples):\n",
        "  \"\"\"Retrieves ingredients from a data set.\"\"\"\n",
        "\n",
        "  return list(map(lambda sample: sample[3], foods))\n",
        "\n",
        "def encode_samples(samples):\n",
        "  \"\"\"Encodes food samples to use as inputs to a model.\"\"\"\n",
        "  sample_descriptions = list(map(lambda sample: sample[1:3], samples))\n",
        "  sample_ingredients = list(map(lambda sample: sample[3], samples))\n",
        "  encoded_data_set = []\n",
        "  encoded_descriptions = food_descriptions_encoder\\\n",
        "    .transform(sample_descriptions)\\\n",
        "    .toarray()\n",
        "  encoded_ingredients = ingredients_encoder.transform(sample_ingredients)\n",
        "\n",
        "  for i in range(len(samples)):\n",
        "    encoded_data_set.append(np.concatenate([encoded_descriptions[i], encoded_ingredients[i]]))\n",
        "  \n",
        "  return encoded_data_set"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB9W8MM8nR4C",
        "outputId": "0d3c33dd-68ec-4a3b-87df-58273c42fef4"
      },
      "source": [
        "# Encoders.\n",
        "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer, OneHotEncoder\n",
        "\n",
        "food_descriptions_encoder = OneHotEncoder()\n",
        "food_descriptions_encoder.fit(get_descriptions(foods))\n",
        "ingredients_encoder = MultiLabelBinarizer()\n",
        "ingredients_encoder.fit(get_ingredients(foods))\n",
        "\n",
        "print(f'Food descriptions:', food_descriptions_encoder.categories_)\n",
        "print(f'Ingredients ({len(ingredients_encoder.classes_)}):', ingredients_encoder.classes_)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Food descriptions: [array(['chewy', 'crunchy', 'liquid', 'mashed', 'solid', 'thick'],\n",
            "      dtype=object), array(['cool', 'normal', 'warm'], dtype=object)]\n",
            "Ingredients (48): ['almond' 'anchovy' 'apple' 'arugula' 'banana' 'bay leaf' 'bean'\n",
            " 'bell pepper' 'black pepper' 'blueberry' 'butter' 'carrot' 'cheese'\n",
            " 'chickpea' 'chili' 'chocolate' 'cookies' 'coriander' 'cranberry' 'cumin'\n",
            " 'egg' 'flour' 'garlic' 'ginger' 'kiwi' 'mango' 'mayonnaise' 'milk'\n",
            " 'mushroom' 'oil' 'okra' 'olive' 'onion' 'pea' 'peanut' 'pineapple'\n",
            " 'potato' 'red pepper' 'rice' 'salt' 'skim milk' 'spinach' 'squash'\n",
            " 'strawberry' 'sugar' 'tomato' 'tumeric' 'vanilla']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfXMO9YFU1uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c58ed7-5247-46bc-8634-0a38a697c146"
      },
      "source": [
        "# Encode, randomize and split data set.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = encode_samples(foods)\n",
        "y = list(map(lambda sample: sample[0], foods))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "print('Training set size:', len(y_train))\n",
        "print('Testing set size:', len(y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size: 21\n",
            "Testing set size: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXDufIHPfj5S"
      },
      "source": [
        "# Data-related utility functions.\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def train(model_class, highlight=False, **args):\n",
        "  \"\"\"Trains a Scikit-Learn-based model.\"\"\"\n",
        "  model = model_class(**args)\n",
        "  cross_validation = cross_val_score(model, X_train, y_train, cv=4)\n",
        "  cv_mean_score = round(cross_validation.mean(), 3)\n",
        "  training_set_score = round(model.fit(X_train, y_train).score(X_test, y_test), 3)\n",
        "\n",
        "  arg_str = ', '.join([f'{key}={args[key]}' for key in args])\n",
        "  name = f'{model_class.__name__}({arg_str})'\n",
        "  output = f'{name.ljust(40, \".\")} {cv_mean_score}, {training_set_score}'\n",
        "\n",
        "  if (highlight):\n",
        "    output += ' **'\n",
        "\n",
        "  print(output)\n",
        "\n",
        "  return None"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCz6klBHUX6r"
      },
      "source": [
        "# [Nearest Neighbours](https://scikit-learn.org/stable/modules/neighbors.html)\n",
        "\n",
        "Scikit-learn supports three nearest neighbours algorithms:\n",
        "- [Brute-force](https://scikit-learn.org/stable/modules/neighbors.html#brute-force).\n",
        "- [K-D Tree](https://scikit-learn.org/stable/modules/neighbors.html#k-d-tree): best for low dimensional data (D < 20).\n",
        "- [Ball Tree](https://scikit-learn.org/stable/modules/neighbors.html#ball-tree): better for high dimensional data.\n",
        "\n",
        "## Summary\n",
        "\n",
        "- Higher K is better.\n",
        "- Uniform weights might be slightly better than distance weights.\n",
        "- Top performers: Uniform KNN (K=15)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUFGKB8uMcya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61d8ad8-ad33-4886-b396-d6f04ce5d320"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "\n",
        "train(KNN, n_neighbors=3, weights='distance')\n",
        "train(KNN, n_neighbors=15, weights='distance')\n",
        "train(KNN, n_neighbors=1, weights='uniform')\n",
        "train(KNN, n_neighbors=3, weights='uniform')\n",
        "train(KNN, n_neighbors=7, weights='uniform')\n",
        "train(KNN, n_neighbors=15, weights='uniform', highlight=True)\n",
        "# train(KNN, n_neighbors=20, weights='uniform')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(n_neighbors=3, weights=distance) 0.292, 0.429\n",
            "KNeighborsClassifier(n_neighbors=15, weights=distance) 0.475, 0.286\n",
            "KNeighborsClassifier(n_neighbors=1, weights=uniform) 0.392, 0.429\n",
            "KNeighborsClassifier(n_neighbors=3, weights=uniform) 0.292, 0.429\n",
            "KNeighborsClassifier(n_neighbors=7, weights=uniform) 0.433, 0.571\n",
            "KNeighborsClassifier(n_neighbors=15, weights=uniform) 0.525, 0.286 **\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3SgkjX8Wpck"
      },
      "source": [
        "# [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees)\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d3T5PaZWXz4"
      },
      "source": [
        "# [Stochastic Gradient Descent](https://scikit-learn.org/stable/modules/sgd.html)\n",
        "\n",
        "Requires a lot of data (>100k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr9d6t-UW18b"
      },
      "source": [
        "# [Support Vector Machine](https://scikit-learn.org/stable/modules/svm.html)\n",
        "\n",
        "## Summary\n",
        "\n",
        "- Higher polynomial is better.\n",
        "- Lower C is better for RBF.\n",
        "- Linear doesn't work very well.\n",
        "- Top performers:\n",
        "  1. SVC(C=10.0, gamma=0.63, kernel=rbf)\n",
        "  2. SVC(C=4.0, gamma=1.0, kernel=rbf)\n",
        "  3. SVC(C=10.0, gamma=1.22, kernel=rbf)\n",
        "  4. SVC(degree=10, kernel=poly)\n",
        "  5. SVC(kernel=sigmoid)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q_ufoDQZj7w",
        "outputId": "6f04b591-435e-4915-a122-46e4048d8584"
      },
      "source": [
        "# SVC: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Linear\n",
        "train(SVC, kernel='linear')\n",
        "\n",
        "# Polynomial\n",
        "train(SVC, degree=3, kernel='poly')\n",
        "train(SVC, degree=10, kernel='poly', highlight=True)\n",
        "train(SVC, degree=20, kernel='poly')\n",
        "\n",
        "# Radial basis function\n",
        "train(SVC, C=0.01, kernel='rbf')\n",
        "train(SVC, C=0.1, kernel='rbf')\n",
        "train(SVC, C=0.1, gamma=0.1, kernel='rbf')\n",
        "train(SVC, C=0.1, gamma=1.0, kernel='rbf')\n",
        "train(SVC, C=0.1, gamma=10.0, kernel='rbf')\n",
        "train(SVC, C=1.0, kernel='rbf')\n",
        "train(SVC, C=4.0, kernel='rbf')\n",
        "train(SVC, C=4.0, gamma=0.1, kernel='rbf')\n",
        "train(SVC, C=4.0, gamma=0.11, kernel='rbf', highlight=True)\n",
        "train(SVC, C=4.0, gamma=0.12, kernel='rbf')\n",
        "train(SVC, C=4.0, gamma=0.15, kernel='rbf')\n",
        "train(SVC, C=4.0, gamma=0.2, kernel='rbf')\n",
        "train(SVC, C=4.0, gamma=0.5, kernel='rbf')\n",
        "train(SVC, C=4.0, gamma=1.0, kernel='rbf', highlight=True)\n",
        "train(SVC, C=4.0, gamma=2.0, kernel='rbf')\n",
        "train(SVC, C=4.0, gamma=3.0, kernel='rbf')\n",
        "train(SVC, C=4.0, gamma=4.0, kernel='rbf', highlight=True)\n",
        "train(SVC, C=4.0, gamma=5.0, kernel='rbf')\n",
        "train(SVC, C=4.0, gamma=10.0, kernel='rbf')\n",
        "train(SVC, C=5.0, kernel='rbf')\n",
        "train(SVC, C=8.0, kernel='rbf')\n",
        "train(SVC, C=10.0, kernel='rbf')\n",
        "train(SVC, C=10.0, gamma=0.1, kernel='rbf')\n",
        "train(SVC, C=10.0, gamma=0.63, kernel='rbf', highlight=True)\n",
        "train(SVC, C=10.0, gamma=1.0, kernel='rbf')\n",
        "train(SVC, C=10.0, gamma=1.22, kernel='rbf', highlight=True)\n",
        "train(SVC, C=10.0, gamma=4.0, kernel='rbf', highlight=True)\n",
        "train(SVC, C=10.0, gamma=10.0, kernel='rbf')\n",
        "\n",
        "# Sigmoid\n",
        "train(SVC, kernel='sigmoid', highlight=True)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC(kernel=linear)...................... 0.383, 0.429\n",
            "SVC(degree=3, kernel=poly).............. 0.425, 0.571\n",
            "SVC(degree=10, kernel=poly)............. 0.575, 0.571 **\n",
            "SVC(degree=20, kernel=poly)............. 0.575, 0.714\n",
            "SVC(C=0.01, kernel=rbf)................. 0.425, 0.714\n",
            "SVC(C=0.1, kernel=rbf).................. 0.425, 0.714\n",
            "SVC(C=0.1, gamma=0.1, kernel=rbf)....... 0.425, 0.714\n",
            "SVC(C=0.1, gamma=1.0, kernel=rbf)....... 0.475, 0.714\n",
            "SVC(C=0.1, gamma=10.0, kernel=rbf)...... 0.475, 0.714\n",
            "SVC(C=1.0, kernel=rbf).................. 0.375, 0.571\n",
            "SVC(C=4.0, kernel=rbf).................. 0.342, 0.571\n",
            "SVC(C=4.0, gamma=0.1, kernel=rbf)....... 0.342, 0.571\n",
            "SVC(C=4.0, gamma=0.11, kernel=rbf)...... 0.342, 0.571 **\n",
            "SVC(C=4.0, gamma=0.12, kernel=rbf)...... 0.342, 0.571\n",
            "SVC(C=4.0, gamma=0.15, kernel=rbf)...... 0.383, 0.571\n",
            "SVC(C=4.0, gamma=0.2, kernel=rbf)....... 0.383, 0.571\n",
            "SVC(C=4.0, gamma=0.5, kernel=rbf)....... 0.475, 1.0\n",
            "SVC(C=4.0, gamma=1.0, kernel=rbf)....... 0.475, 1.0 **\n",
            "SVC(C=4.0, gamma=2.0, kernel=rbf)....... 0.475, 0.714\n",
            "SVC(C=4.0, gamma=3.0, kernel=rbf)....... 0.475, 0.714\n",
            "SVC(C=4.0, gamma=4.0, kernel=rbf)....... 0.475, 0.714 **\n",
            "SVC(C=4.0, gamma=5.0, kernel=rbf)....... 0.475, 0.714\n",
            "SVC(C=4.0, gamma=10.0, kernel=rbf)...... 0.475, 0.714\n",
            "SVC(C=5.0, kernel=rbf).................. 0.342, 0.571\n",
            "SVC(C=8.0, kernel=rbf).................. 0.342, 0.571\n",
            "SVC(C=10.0, kernel=rbf)................. 0.342, 0.571\n",
            "SVC(C=10.0, gamma=0.1, kernel=rbf)...... 0.342, 0.571\n",
            "SVC(C=10.0, gamma=0.63, kernel=rbf)..... 0.475, 1.0 **\n",
            "SVC(C=10.0, gamma=1.0, kernel=rbf)...... 0.475, 1.0\n",
            "SVC(C=10.0, gamma=1.22, kernel=rbf)..... 0.475, 0.857 **\n",
            "SVC(C=10.0, gamma=4.0, kernel=rbf)...... 0.475, 0.714 **\n",
            "SVC(C=10.0, gamma=10.0, kernel=rbf)..... 0.475, 0.714\n",
            "SVC(kernel=sigmoid)..................... 0.333, 0.286 **\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g0aUDTMOZiP"
      },
      "source": [
        "# [SVC Parameter Tuning](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html)\n",
        "\n",
        "Some [scoring functions](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) explained:\n",
        "\n",
        "- [Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
        "- [Average precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html)\n",
        "- [Recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
        "\n",
        "Glossary:\n",
        "\n",
        "- [Precision](https://developers.google.com/machine-learning/glossary#precision): rate at which model is correct (kind of like \"engineering precision\").\n",
        "- [Recall](https://developers.google.com/machine-learning/glossary#recall): rate at which model can make successful predictions (kind of like \"engineering accuracy\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cfFMXKmOl_d"
      },
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# parameters = [\n",
        "#   {\n",
        "#     'C': range(4, 31),\n",
        "#     'gamma': list(map(lambda g: g / 100, list(range(10, 1001)))),\n",
        "#     'kernel': ['rbf'],\n",
        "#   }\n",
        "# ]\n",
        "\n",
        "# score_fns = [\n",
        "#   # 'accuracy',\n",
        "#   'recall_macro',\n",
        "# ]\n",
        "\n",
        "# for score_fn in score_fns:\n",
        "#     print(f'Tuning hyper-parameters for {score_fn}...')\n",
        "#     print()\n",
        "\n",
        "#     model = GridSearchCV(SVC(), parameters, scoring=score_fn)\n",
        "#     model.fit(X_train, y_train)\n",
        "\n",
        "#     print(f'Best parameters set for {score_fn}')\n",
        "#     print()\n",
        "#     print(model.best_params_)\n",
        "#     print()\n",
        "\n",
        "#     print('Detailed classification report:')\n",
        "#     print()\n",
        "  \n",
        "#     y_true, y_pred = y_test, model.predict(X_test)\n",
        "#     print(classification_report(y_true, y_pred))\n",
        "#     print()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMkcbqZ3muum"
      },
      "source": [
        "# TensorFlow [Linear Classifier](https://www.tensorflow.org/tutorials/estimator/linear)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYq8ydVOm96A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "b3a4fa26-2dd1-433e-a4c2-ad0cabd32bf3"
      },
      "source": [
        "# Linear classifier using TensorFlow\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "features = []\n",
        "\n",
        "for category in food_descriptions_encoder.categories_:\n",
        "  features.extend(category)\n",
        "\n",
        "features.extend(ingredients_encoder.classes_)\n",
        "\n",
        "X_train_df = pd.DataFrame(X_train, columns=features)\n",
        "X_eval_df = pd.DataFrame(X_test, columns=features)\n",
        "y_train_df = pd.DataFrame(y_train, columns=['label'])\n",
        "y_eval_df = pd.DataFrame(y_test, columns=['label'])\n",
        "\n",
        "X_train_df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chewy</th>\n",
              "      <th>crunchy</th>\n",
              "      <th>liquid</th>\n",
              "      <th>mashed</th>\n",
              "      <th>solid</th>\n",
              "      <th>thick</th>\n",
              "      <th>cool</th>\n",
              "      <th>normal</th>\n",
              "      <th>warm</th>\n",
              "      <th>almond</th>\n",
              "      <th>anchovy</th>\n",
              "      <th>apple</th>\n",
              "      <th>arugula</th>\n",
              "      <th>banana</th>\n",
              "      <th>bay leaf</th>\n",
              "      <th>bean</th>\n",
              "      <th>bell pepper</th>\n",
              "      <th>black pepper</th>\n",
              "      <th>blueberry</th>\n",
              "      <th>butter</th>\n",
              "      <th>carrot</th>\n",
              "      <th>cheese</th>\n",
              "      <th>chickpea</th>\n",
              "      <th>chili</th>\n",
              "      <th>chocolate</th>\n",
              "      <th>cookies</th>\n",
              "      <th>coriander</th>\n",
              "      <th>cranberry</th>\n",
              "      <th>cumin</th>\n",
              "      <th>egg</th>\n",
              "      <th>flour</th>\n",
              "      <th>garlic</th>\n",
              "      <th>ginger</th>\n",
              "      <th>kiwi</th>\n",
              "      <th>mango</th>\n",
              "      <th>mayonnaise</th>\n",
              "      <th>milk</th>\n",
              "      <th>mushroom</th>\n",
              "      <th>oil</th>\n",
              "      <th>okra</th>\n",
              "      <th>olive</th>\n",
              "      <th>onion</th>\n",
              "      <th>pea</th>\n",
              "      <th>peanut</th>\n",
              "      <th>pineapple</th>\n",
              "      <th>potato</th>\n",
              "      <th>red pepper</th>\n",
              "      <th>rice</th>\n",
              "      <th>salt</th>\n",
              "      <th>skim milk</th>\n",
              "      <th>spinach</th>\n",
              "      <th>squash</th>\n",
              "      <th>strawberry</th>\n",
              "      <th>sugar</th>\n",
              "      <th>tomato</th>\n",
              "      <th>tumeric</th>\n",
              "      <th>vanilla</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   chewy  crunchy  liquid  mashed  ...  sugar  tomato  tumeric  vanilla\n",
              "0    0.0      0.0     0.0     0.0  ...    0.0     0.0      0.0      0.0\n",
              "1    0.0      0.0     0.0     0.0  ...    0.0     0.0      0.0      0.0\n",
              "2    0.0      0.0     0.0     0.0  ...    0.0     0.0      0.0      0.0\n",
              "3    0.0      0.0     0.0     1.0  ...    0.0     1.0      1.0      0.0\n",
              "4    0.0      0.0     0.0     0.0  ...    1.0     1.0      0.0      0.0\n",
              "\n",
              "[5 rows x 57 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "nk4Hz3tx3MjX",
        "outputId": "7662c1d6-bb73-4a67-8d27-97afac96b2ea"
      },
      "source": [
        "X_train_df.describe()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chewy</th>\n",
              "      <th>crunchy</th>\n",
              "      <th>liquid</th>\n",
              "      <th>mashed</th>\n",
              "      <th>solid</th>\n",
              "      <th>thick</th>\n",
              "      <th>cool</th>\n",
              "      <th>normal</th>\n",
              "      <th>warm</th>\n",
              "      <th>almond</th>\n",
              "      <th>anchovy</th>\n",
              "      <th>apple</th>\n",
              "      <th>arugula</th>\n",
              "      <th>banana</th>\n",
              "      <th>bay leaf</th>\n",
              "      <th>bean</th>\n",
              "      <th>bell pepper</th>\n",
              "      <th>black pepper</th>\n",
              "      <th>blueberry</th>\n",
              "      <th>butter</th>\n",
              "      <th>carrot</th>\n",
              "      <th>cheese</th>\n",
              "      <th>chickpea</th>\n",
              "      <th>chili</th>\n",
              "      <th>chocolate</th>\n",
              "      <th>cookies</th>\n",
              "      <th>coriander</th>\n",
              "      <th>cranberry</th>\n",
              "      <th>cumin</th>\n",
              "      <th>egg</th>\n",
              "      <th>flour</th>\n",
              "      <th>garlic</th>\n",
              "      <th>ginger</th>\n",
              "      <th>kiwi</th>\n",
              "      <th>mango</th>\n",
              "      <th>mayonnaise</th>\n",
              "      <th>milk</th>\n",
              "      <th>mushroom</th>\n",
              "      <th>oil</th>\n",
              "      <th>okra</th>\n",
              "      <th>olive</th>\n",
              "      <th>onion</th>\n",
              "      <th>pea</th>\n",
              "      <th>peanut</th>\n",
              "      <th>pineapple</th>\n",
              "      <th>potato</th>\n",
              "      <th>red pepper</th>\n",
              "      <th>rice</th>\n",
              "      <th>salt</th>\n",
              "      <th>skim milk</th>\n",
              "      <th>spinach</th>\n",
              "      <th>squash</th>\n",
              "      <th>strawberry</th>\n",
              "      <th>sugar</th>\n",
              "      <th>tomato</th>\n",
              "      <th>tumeric</th>\n",
              "      <th>vanilla</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>21.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.476190</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.190476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.358569</td>\n",
              "      <td>0.507093</td>\n",
              "      <td>0.462910</td>\n",
              "      <td>0.497613</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.507093</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.402374</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.358569</td>\n",
              "      <td>0.462910</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.462910</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.358569</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.358569</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.483046</td>\n",
              "      <td>0.511766</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.436436</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.511766</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.507093</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.358569</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.483046</td>\n",
              "      <td>0.218218</td>\n",
              "      <td>0.402374</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.300793</td>\n",
              "      <td>0.462910</td>\n",
              "      <td>0.436436</td>\n",
              "      <td>0.402374</td>\n",
              "      <td>0.402374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           chewy    crunchy     liquid  ...     tomato    tumeric    vanilla\n",
              "count  21.000000  21.000000  21.000000  ...  21.000000  21.000000  21.000000\n",
              "mean    0.047619   0.047619   0.047619  ...   0.238095   0.190476   0.190476\n",
              "std     0.218218   0.218218   0.218218  ...   0.436436   0.402374   0.402374\n",
              "min     0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000\n",
              "25%     0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000\n",
              "50%     0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000\n",
              "75%     0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000\n",
              "max     1.000000   1.000000   1.000000  ...   1.000000   1.000000   1.000000\n",
              "\n",
              "[8 rows x 57 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6s_D0Rc5_Bu"
      },
      "source": [
        "# Feature columns\n",
        "tf_columns = []\n",
        "\n",
        "for feature in features:\n",
        "  tf_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature, [0, 1]))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLWhgFAo7KuL"
      },
      "source": [
        "# Input functions\n",
        "\n",
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "    \n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    return ds\n",
        "  \n",
        "  return input_function\n",
        "\n",
        "train_input_fn = make_input_fn(X_train_df, y_train_df)\n",
        "eval_input_fn = make_input_fn(X_eval_df, y_eval_df, num_epochs=1, shuffle=False)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "pQO292j38XyF",
        "outputId": "1274b6a3-ba1a-44b1-e0cd-284119e4c8f3"
      },
      "source": [
        "# Linear estimator\n",
        "linear_est = tf.estimator.LinearClassifier(feature_columns=tf_columns)\n",
        "linear_est.train(train_input_fn)\n",
        "result = linear_est.evaluate(eval_input_fn)\n",
        "\n",
        "print(result)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpuyl0t3h9\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpuyl0t3h9', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-124a46bb3dbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Linear estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlinear_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlinear_est\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_est\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1202\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n\u001b[0;32m-> 1204\u001b[0;31m                                            self.config)\n\u001b[0m\u001b[1;32m   1205\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    943\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m           sparse_combiner=sparse_combiner)\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     super(LinearClassifierV2, self).__init__(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_linear_model_fn_v2\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0msparse_combiner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_combiner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         features=features)\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;31m# In TRAIN mode, create optimizer and assign global_step variable to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_linear_model_fn_builder_v2\u001b[0;34m(units, feature_columns, sparse_combiner, features)\u001b[0m\n\u001b[1;32m    600\u001b[0m       \u001b[0msparse_combiner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_combiner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       name='linear/linear_model')\n\u001b[0;32m--> 602\u001b[0;31m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m   \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m               with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m    785\u001b[0m                   self._compute_dtype_object):\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:1671 call  *\n        return self.layer(features)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:1499 call  *\n        weighted_sum = fc_v2._create_weighted_sum(  # pylint: disable=protected-access\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2138 _create_weighted_sum  **\n        weight_var=weight_var)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2226 _create_categorical_column_weighted_sum\n        state_manager)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:3582 get_sparse_tensors\n        transformation_cache.get(self, state_manager), None)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2355 get\n        transformed = column.transform_feature(self, state_manager)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:3560 transform_feature\n        return self._transform_input_tensor(input_tensor, state_manager)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:3528 _transform_input_tensor\n        self.key, self.dtype, input_tensor.dtype))\n\n    ValueError: Column dtype and SparseTensors dtype must be compatible. key: almond, column dtype: <dtype: 'int64'>, tensor dtype: <dtype: 'float32'>\n"
          ]
        }
      ]
    }
  ]
}